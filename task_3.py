# -*- coding: utf-8 -*-
"""Task - 3

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1N9gSzIHZ5YhslADlkdUFuidUrZeE9IL_
"""

import pandas as pd
import numpy as np
import math
import matplotlib.pyplot as plt
import matplotlib
import seaborn as sns
import scipy as sp
import statsmodels as sm

df=pd.read_csv('DATA - 3 (1).csv')
df

df.head()

df.dtypes

df.describe()

df.nunique()

df.nativeLanguage.unique()

df.gender.unique()

df.city.unique()

df.country.unique()

df.section.unique()

df.cue.unique()

df.R1.unique()

df.R2.unique()

df.R3.unique()

df=df.copy()

df.nativeLanguage.value_counts()

df['nativeLanguage_num']=pd.factorize(df.nativeLanguage)[0]

df

df['gender_num']=pd.factorize(df.gender)[0]

df

df['city_num']=pd.factorize(df.city)[0]

df

df['country_num']=pd.factorize(df.country)[0]

df

df['section_num']=pd.factorize(df.section)[0]

df

df['cue_num']=pd.factorize(df.cue)[0]

df

df['R1_num']=pd.factorize(df.R1)[0]
df['R2_num']=pd.factorize(df.R2)[0]
df['R3_num']=pd.factorize(df.R3)[0]
df

df.dtypes

df1=df.select_dtypes(include=['int64']).copy()

df1

df1.nunique()

import sklearn
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split

X=df1.iloc[:,:-1]
y=df1.iloc[:,-1]
X_train,X_test, y_train, y_test=train_test_split(X,y,test_size=0.25, random_state=0)

X_train

X_test

y_train

y_test

from sklearn.linear_model import LinearRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, mean_squared_error

ler=LinearRegression()

ler.fit(X_train,y_train)

predictions=ler.predict(X_test)

predictions

predictions=predictions.astype(int)

import warnings
warnings.filterwarnings("ignore", category=DeprecationWarning)

from math import sqrt

accuracy = accuracy_score(y_test, predictions)
precision = precision_score(y_test, predictions, average='weighted',zero_division=1)
recall = recall_score(y_test, predictions, average='weighted')
rmse = sqrt(mean_squared_error(y_test, predictions))

print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("Root Mean Squared Error (RMSE):", rmse)

from sklearn.linear_model import LinearRegression
from sklearn.model_selection import GridSearchCV
model = LinearRegression()
param_grid = {
    'fit_intercept': [True, False],
    'positive': [True, False]
}
grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5)
grid_search.fit(X_train, y_train)
best_params = grid_search.best_params_
best_model = grid_search.best_estimator_

df1

df1.sample(10000)

import scipy.stats as stats

sample_mean=df1.age.sample(10000).mean()
sample_mean

sample_std=df1.age.sample(10000).std()
sample_std

population_mean=df.age.mean()
population_mean

population_std=df.age.std()
population_std

import warnings
warnings.filterwarnings("ignore", category=RuntimeWarning)

z_score = (sample_mean - population_mean) / (population_std / np.sqrt(len(df1.age.sample(10000))))
print("Z-score:", z_score)

alpha=0.05

critical_z_left = stats.norm.ppf(alpha / 2)
critical_z_right = -critical_z_left
critical_z = stats.norm.ppf(alpha)

if z_score < critical_z_left or z_score > critical_z_right:
    print("Reject the null hypothesis: The sample mean is significantly different from the population mean.")
else:
    print("Fail to reject the null hypothesis: The sample mean is not significantly different from the population mean.")

f_statistic, p_value = stats.f_oneway(df1.R1_num, df1.R2_num, df1.R3_num)

print("F-statistic:", f_statistic)
print("P-value:", p_value)

alpha = 0.05
if p_value < alpha:
    print("Reject the null hypothesis: There are significant differences between the means.")
else:
    print("Fail to reject the null hypothesis: There are no significant differences between the means.")